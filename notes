Forex phillipsCapital
https://www.phillipcapital.in/9.13.0.0.zip

http://phillipcapital.in/java.zip

FXCM
https://fxcm.github.io/rest-api-docs/#section/Overview
https://apiwiki.fxcorporate.com/api/RestAPI/JavaRestClient.zip
We have RSI example program in Python for REST API:

https://apiwiki.fxcorporate.com/api/StrategyRealCaseStudy/RestAPI/RsiStrategy.zip

and Java RSI program for Java API:

https://apiwiki.fxcorporate.com/api/StrategyRealCaseStudy/JavaAPI/FXCM_Java_API_Tutorial_RsiSignal_Strategy.zip

 

you may need to translate the Python to Java or to use some parts from the Java program.


---Questions--
2. difference between fail fast and fail safe iterator?
3. How linkedHashmap maintains order --> using doubly linked list
4. How checked exceptions are wrapped under unchecked exceptions?
5 How to make callback class or method?
6. What is repeatable annotation?
7. How listner or callback internally works?

--links--
https://stackoverflow.com/questions/8192223/object-cloning-with-out-implementing-cloneable-interface
https://javarevisited.blogspot.com/2017/04/difference-between-autowired-and-inject-annotation-in-spring-framework.html#at_pco=smlwn-1.0&at_si=5b6cfdbb332493d6&at_ab=per-2&at_pos=0&at_tot=1


--java memory mgmt--
https://betsol.com/2017/06/java-memory-management-for-java-virtual-machine-jvm/
https://www.journaldev.com/2856/java-jvm-memory-model-memory-management-in-java

--spring-
https://docs.spring.io/spring-security/site/docs/5.0.6.RELEASE/reference/htmlsingle/#jc-authentication-userdetailsservice
https://aboullaite.me/the-magic-behind-the-magic-spring-boot-autoconfiguration/
http://dhaval-shah.com/unraveling-the-magic-behind-spring-boot/

--Spring boot program args--
--spring.devtools.restart.additional-paths=K:/Technologies/SpringBoot/spring_boot_properties/ --spring.config.additional-location="file:K:/Technologies/SpringBoot/spring_boot_properties/application.properties" --spring.profiles.active=prod

--Spring Boot--
-----------------------------------------------------Spring Boot------------------------------------
https://aboullaite.me/the-magic-behind-the-magic-spring-boot-autoconfiguration/
http://dhaval-shah.com/unraveling-the-magic-behind-spring-boot/


-----------Spring Boot Cloud Best Practices----------------
https://www.vinaysahni.com/best-practices-for-building-a-microservice-architecture
https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance
https://github.com/Netflix/zuul/wiki
https://developers.redhat.com/blog/2016/12/09/spring-cloud-for-microservices-compared-to-kubernetes/
https://dzone.com/articles/deploying-microservices-spring-cloud-vs-kubernetes
https://dzone.com/articles/microservice-architecture-with-spring-cloud-and-do

--Webflux Reactive stack vs Servlet stack--
https://medium.com/@the.raj.saxena/springboot-2-performance-servlet-stack-vs-webflux-reactive-stack-528ad5e9dadc

--Spring Security--
https://docs.spring.io/spring-security/site/docs/5.0.6.RELEASE/reference/htmlsingle/#jc-authentication-userdetailsservice



-Spring rest --
https://www.baeldung.com/rest-with-spring-series/

--Spring Security--
https://www.baeldung.com/security-spring

--Spring Persistence API--
https://www.baeldung.com/persistence-with-spring-series/


---Concurrency--
https://docs.oracle.com/javase/tutorial/essential/concurrency/interfere.html
https://techdifferences.com/difference-between-thread-class-and-runnable-interface-in-java.html

-----------To enable Thead visualization in JVisualVM use below VM arguments--
-Dcom.sun.management.jmxremote
-Dcom.sun.management.jmxremote.port=9010
-Dcom.sun.management.jmxremote.local.only=false
-Dcom.sun.management.jmxremote.authenticate=false
-Dcom.sun.management.jmxremote.ssl=false

---------------------------------------------------------


-----------------------Collection Java Docs---
https://docs.oracle.com/javase/8/docs/technotes/guides/collections/overview.html

--updated to do--
https://www.pearsonfrank.com/blog/java-interview-questions/
http://www.java2novice.com/java_interview_questions/countdownlatch-cyclicbarrier/
https://stackoverflow.com/questions/8192223/object-cloning-with-out-implementing-cloneable-interface
https://javapapers.com/core-java/java-weak-reference/


https://www.journaldev.com/1330/java-collections-interview-questions-and-answers
https://dzone.com/articles/lifecycle-of-a-request-response-process-for-a-spri
https://aboullaite.me/the-magic-behind-the-magic-spring-boot-autoconfiguration/


------Oracle Java Tutorial---
https://docs.oracle.com/javase/tutorial/tutorialLearningPaths.html
https://docs.oracle.com/javase/tutorial/essential/exceptions/advantages.html
https://www.google.co.in/amp/s/www.datasciencelearner.com/how-to-build-a-chatbot-rasa-complete-guide/amp/
https://github.com/RasaHQ/rasa_core/tree/master/examples/restaurantbot


https://github.com/eugenp/tutorials/tree/master/spring-rest
https://www.baeldung.com/rest-template

–-------micro service--


-dmaven.multimoduleprojectdirectory system property is not set eclipse


--------cloudfoundry----
1. bootstrap.properties
2. 

cf login -a https://api.run.pivotal.io -u karmakarsurjeet@gmail.com

cf push my-hello-app2 -p SpringBootTest-0.0.1-SNAPSHOT.jar


https://github.com/sbolchetwar/microservices-training

https://github.com/Pivotal-Field-Engineering/spring-boot-data-rest-demo/blob/master/README.md

https://github.com/sbolchetwar/microservices-training

https://github.com/Pivotal-Field-Engineering/spring-boot-data-rest-demo/blob/master/README.md


Zuul --> dynamic routing, callback filter
Eureka Server --> Service Directory


--research--
lombok
memcached
kubernetes
docker
circuit breaker
kerberos
site minder


Hystrix --> fallback mechanism

--links--
https://www.baeldung.com/bootstraping-a-web-application-with-spring-and-java-based-configuration
https://www.baeldung.com/simplifying-the-data-access-layer-with-spring-and-java-generics
https://www.baeldung.com/security-spring

http://www.springboottutorial.com/microservices-with-spring-boot-part-4-ribbon-for-load-balancing
https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb4b?source=email-8980675f0007-1548037986615-digest.reader------0-49------------------f37f40d4_6de1_418a_98b4_4696066c7afc-1&sectionName=top



https://o7planning.org/en/11665/spring-boot-hibernate-and-spring-transaction-tutorial
https://www.journaldev.com/3481/hibernate-session-merge-vs-update-save-saveorupdate-persist-example
https://auth0.com/blog/what-is-and-how-does-single-sign-on-work/


https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb4b
https://www.javaworld.com/article/2076971/java-concurrency/how-the-java-virtual-machine-performs-thread-synchronization.html

https://www.javaworld.com/blog/under-the-hood/
https://github.com/eugenp/tutorials

--Stylesheet--
  Sass   [ http://sass-lang.com   ]
  Less   [ http://lesscss.org     ]
  Stylus [ http://stylus-lang.com ]
  
  
  https://martinfowler.com/articles/mocksArentStubs.html
  
  
  
  -----------------------------
  https://dzone.com/articles/building-a-web-app-using-spring-boot-angular-6-and
  https://github.com/JohnnyLe/Modern-Ecommerce
  https://github.com/jhipster/jhipster-sample-app



-----------------------------------------------Commands on Putty for AWS Docker-------------------------------------------------------> 
------------first time usage-----------------  
sudo yum update
sudo yum install -y docker
sudo service docker start 
 
 
-------create a file with below content and name it as ‘Dockerfile’ ------------>
  
FROM openjdk:8
ADD TropicalFruits-API.jar TropicalFruits-API.jar
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "TropicalFruits-API.jar"] 


FROM openjdk:8
ADD SpringBootInitializerDemo-0.0.1-SNAPSHOT.jar SpringBootInitializerDemo.jar
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "SpringBootInitializerDemo.jar"] 
<-----------------End of file-----------------------------------------------------


--------------------to Copy the jar in the instance ---------------------------
//to create image(go to path where jar and above file is kept and run below command)
sudo docker build -t tropical-fruits-docker-image .
//to check the created docker images
sudo docker images --filter reference=tropical-fruits-docker-image
 
--------------------------to run the docker image-------------------------------
//run the image(first port is the port configured in ec2, second one is of spring application)hit the application e.g. ‘ http://ec2-18-218-83-254.us-east-2.compute.amazonaws.com/’
sudo docker run -p 443:8080 tropical-fruits-docker-image   


<----------------------------------------------------------------end of commands---------------------------------------------------

---PCF cloud config server--
https://github.com/Java-Techie-jt/cloud-config-pivotal-cloud-foundry


-----------Other design patterns----
1.Enterprise pattern
https://www.martinfowler.com/articles/enterprisePatterns.html


-----------------------Kafka----------------
zookeeper-server-start.bat ../../config/zookeeper.properties
kafka-server-start.bat ../../config/server-2.properties
kafka-server-start.bat ../../config/server.properties


kafka-topics.bat --zookeeper localhost:2181 --create --topic simpleTopic --partitions 3 --replication-factor 2
kafka-topics.bat --describe --zookeeper localhost:2181
kafka-topics.bat --delete --topic simpleTopic1 -zookeeper localhost:2181
kafka-topics.bat --zookeeper localhost:2181 --alter --topic simpleTopic --config retention.ms=1000


kafka-consumer-groups.bat --describe --all-groups --bootstrap-server localhost:9092

zookeeper-shell.bat localhost:2181
ls /brokers/ids
ls /brokers/topics
get /brokers/ids/0


/consumers, /brokers/ids, /brokers/topics, /config, /admin/delete_topics, /brokers/seqid, /isr_change_notification, /config/topics, /config/clients

---------------imp links------
https://medium.com/hacking-talent/kafka-all-you-need-to-know-8c7251b49ad0
https://github.com/yahoo/kafka-manager/releases
https://kafka.apache.org/documentation/
http://cloudurable.com/blog/kafka-architecture-low-level/index.html
http://cloudurable.com/blog/kafka-ecosystem/index.html

----------Imp concepts---
-tombstones --> null records. Kafka delete such record after delete.retention.ms time
-Quorum --> Zookeeper cluster


--------------------------------------------------------------------------------------------------------
-> Kafka Publisher (rest impl in progress)
-> Review training materials (deck, code, flow)
-> GKS Demo code, Kafka Stream demo code, Microservice SpringBoot Kafka demo
-> delete topic try and try increasing or reducing replication factor
-> Avro serialization internals
-> current offset and committed offset difference
-> confirmation of message sending from producer to broker and broker to consumer (ack)
-> how exactly once is achieved
-> short zookeeper tutorial
-> Real life use case (How world is using it), bit theory
-> Properties and prod config analysis
-> 


kubectl create secret docker-registry gitlab-registry-secret \
    --docker-server=registry.gitlab.com \
    --docker-username=<your-gitlab-username> \
    --docker-password=<your-gitlab-personal-access-token> \
    --docker-email=<your-email>


spec:
      containers:
        - name: example-container
          image: registry.gitlab.com/your-group/your-project:latest
      imagePullSecrets:
        - name: gitlab-registry-secret


#-----------------------Create snapshot----------------------------------
#!/bin/bash

# Check if PVC name is provided
if [ -z "$1" ]; then
  echo "Usage: $0 <pvc-name>"
  exit 1
fi

PVC_NAME=$1
NAMESPACE="default"  # Adjust the namespace as needed

# Get PV name from PVC
PV_NAME=$(kubectl get pvc $PVC_NAME -n $NAMESPACE -o jsonpath='{.spec.volumeName}')
if [ -z "$PV_NAME" ]; then
  echo "No PV found for PVC $PVC_NAME"
  exit 1
fi

# Get volume handler (EBS volume ID) from PV
VOLUME_HANDLER=$(kubectl get pv $PV_NAME -o jsonpath='{.spec.csi.volumeHandle}')
if [ -z "$VOLUME_HANDLER" ]; then
  echo "No volume handler found for PV $PV_NAME"
  exit 1
fi

echo "PVC Name: $PVC_NAME"
echo "PV Name: $PV_NAME"
echo "Volume Handler: $VOLUME_HANDLER"

# Create snapshot
SNAPSHOT_DESC="Snapshot of volume $VOLUME_HANDLER from PVC $PVC_NAME"
SNAPSHOT_ID=$(aws ec2 create-snapshot --volume-id $VOLUME_HANDLER --description "$SNAPSHOT_DESC" --query SnapshotId --output text)
if [ -z "$SNAPSHOT_ID" ]; then
  echo "Failed to create snapshot"
  exit 1
fi

echo "Snapshot ID: $SNAPSHOT_ID"

#-----------------------create_volume_from_snapshot.sh----------------------------------

echo "PVC Name: $PVC_NAME"
echo "PV Name: $PV_NAME"
echo "Volume Handler: $VOLUME_HANDLER"

# Retrieve metadata from the original volume
METADATA=$(aws ec2 describe-volumes --volume-ids $VOLUME_HANDLER --query 'Volumes[0]')
if [ -z "$METADATA" ]; then
  echo "Failed to retrieve volume metadata"
  exit 1
fi

TAGS=$(echo $METADATA | jq -r '.Tags')
KMS_KEY_ID=$(echo $METADATA | jq -r '.KmsKeyId')
VOLUME_TYPE=$(echo $METADATA | jq -r '.VolumeType')
AVAILABILITY_ZONE=$(echo $METADATA | jq -r '.AvailabilityZone')
SIZE=$(echo $METADATA | jq -r '.Size')

echo "Tags: $TAGS"
echo "KMS Key ID: $KMS_KEY_ID"
echo "Volume Type: $VOLUME_TYPE"
echo "Availability Zone: $AVAILABILITY_ZONE"
echo "Size: $SIZE"

# Create a new volume from the snapshot
NEW_VOLUME_ID=$(aws ec2 create-volume --snapshot-id $SNAPSHOT_ID --availability-zone $AVAILABILITY_ZONE --volume-type $VOLUME_TYPE --size $SIZE --encrypted --kms-key-id $KMS_KEY_ID --query VolumeId --output text)
if [ -z "$NEW_VOLUME_ID" ]; then
  echo "Failed to create new volume"
  exit 1
fi

echo "New Volume ID: $NEW_VOLUME_ID"

# Apply tags to the new volume
aws ec2 create-tags --resources $NEW_VOLUME_ID --tags "$TAGS"
if [ $? -ne 0 ]; then
  echo "Failed to apply tags to new volume"
  exit 1
fi

echo "Old Volume ID: $VOLUME_HANDLER"
echo "New Volume ID: $NEW_VOLUME_ID"

#-----------------------create_pvc_from_volume.sh----------------------------------
#!/bin/bash

# Check if all required inputs are provided
if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ]; then
  echo "Usage: $0 <existing-pvc-name> <new-pvc-name> <snapshot-id> <namespace>"
  exit 1
fi

EXISTING_PVC_NAME=$1
NEW_PVC_NAME=$2
SNAPSHOT_ID=$3
NAMESPACE=$4

# Fetch existing PVC metadata
PVC_JSON=$(kubectl get pvc $EXISTING_PVC_NAME -n $NAMESPACE -o json)
if [ $? -ne 0 ]; then
  echo "Failed to fetch PVC $EXISTING_PVC_NAME"
  exit 1
fi

# Extract necessary information from the existing PVC
STORAGE_CLASS=$(echo $PVC_JSON | jq -r '.spec.storageClassName')
ACCESS_MODES=$(echo $PVC_JSON | jq -r '.spec.accessModes')
STORAGE=$(echo $PVC_JSON | jq -r '.spec.resources.requests.storage')

# Fetch the PV associated with the existing PVC
EXISTING_PV_NAME=$(kubectl get pvc $EXISTING_PVC_NAME -n $NAMESPACE -o jsonpath='{.spec.volumeName}')
PV_JSON=$(kubectl get pv $EXISTING_PV_NAME -o json)
if [ $? -ne 0 ]; then
  echo "Failed to fetch PV $EXISTING_PV_NAME"
  exit 1
fi

# Extract necessary information from the existing PV
VOLUME_MODE=$(echo $PV_JSON | jq -r '.spec.volumeMode')
PV_RECLAIM_POLICY=$(echo $PV_JSON | jq -r '.spec.persistentVolumeReclaimPolicy')
VOLUME_HANDLER=$(kubectl get pv $EXISTING_PV_NAME -o jsonpath='{.spec.csi.volumeHandle}')

# Retrieve metadata from the original volume
METADATA=$(aws ec2 describe-volumes --volume-ids $VOLUME_HANDLER --query 'Volumes[0]')
if [ -z "$METADATA" ]; then
  echo "Failed to retrieve volume metadata"
  exit 1
fi

TAGS=$(echo $METADATA | jq -r '.Tags')
KMS_KEY_ID=$(echo $METADATA | jq -r '.KmsKeyId')
VOLUME_TYPE=$(echo $METADATA | jq -r '.VolumeType')
AVAILABILITY_ZONE=$(echo $METADATA | jq -r '.AvailabilityZone')
SIZE=$(echo $METADATA | jq -r '.Size')

# Create a new volume from the snapshot
NEW_VOLUME_ID=$(aws ec2 create-volume --snapshot-id $SNAPSHOT_ID --availability-zone $AVAILABILITY_ZONE --volume-type $VOLUME_TYPE --size $SIZE --encrypted --kms-key-id $KMS_KEY_ID --query VolumeId --output text)
if [ -z "$NEW_VOLUME_ID" ]; then
  echo "Failed to create new volume"
  exit 1
fi

echo "New Volume ID: $NEW_VOLUME_ID"

# Apply tags to the new volume
aws ec2 create-tags --resources $NEW_VOLUME_ID --tags "$TAGS"
if [ $? -ne 0 ]; then
  echo "Failed to apply tags to new volume"
  exit 1
fi

# Generate unique PV name
NEW_PV_NAME="${NEW_PVC_NAME}-pv"

# Create PV YAML
PV_YAML=$(cat <<EOF
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ${NEW_PV_NAME}
spec:
  capacity:
    storage: ${STORAGE}
  volumeMode: ${VOLUME_MODE}
  accessModes: ${ACCESS_MODES}
  persistentVolumeReclaimPolicy: ${PV_RECLAIM_POLICY}
  storageClassName: ${STORAGE_CLASS}
  csi:
    driver: ebs.csi.aws.com
    volumeHandle: ${NEW_VOLUME_ID}
EOF
)

# Create PVC YAML
PVC_YAML=$(cat <<EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ${NEW_PVC_NAME}
  namespace: ${NAMESPACE}
spec:
  accessModes: ${ACCESS_MODES}
  storageClassName: ${STORAGE_CLASS}
  resources:
    requests:
      storage: ${STORAGE}
  volumeName: ${NEW_PV_NAME}
EOF
)

# Create the PV
echo "$PV_YAML" | kubectl apply -f -
if [ $? -ne 0 ]; then
  echo "Failed to create PersistentVolume"
  exit 1
fi

# Create the PVC
echo "$PVC_YAML" | kubectl apply -f -
if [ $? -ne 0 ]; then
  echo "Failed to create PersistentVolumeClaim"
  exit 1
fi

echo "Successfully created PVC ${NEW_PVC_NAME} using volume ID ${NEW_VOLUME_ID}"



--override functionality--
#!/bin/bash

# Define your local file path and S3 bucket
LOCAL_FILE="/path/to/your/local/file"
S3_BUCKET="s3://your-bucket-name"
S3_FILE_PATH="path/in/bucket/to/file"

# Define the override flag
OVERRIDE=false  # Change this to true if you want to force download

# Function to download file from S3
download_from_s3() {
    aws s3 cp "$S3_BUCKET/$S3_FILE_PATH" "$LOCAL_FILE"
    if [ $? -eq 0 ]; then
        echo "Downloaded $S3_BUCKET/$S3_FILE_PATH to $LOCAL_FILE"
    else
        echo "Failed to download $S3_BUCKET/$S3_FILE_PATH" >&2
    fi
}

# Check if the local file does not exist or if override is true
if [ "$OVERRIDE" = true ] || [ ! -f "$LOCAL_FILE" ]; then
    download_from_s3
else
    echo "File $LOCAL_FILE already exists, skipping download."
fi

--------------------
#!/bin/bash

# Define your local file path and S3 bucket
LOCAL_FILE="/path/to/your/local/file"
S3_BUCKET="s3://your-bucket-name"
S3_FILE_PATH="path/in/bucket/to/file"

# Define the override flag
OVERRIDE=false  # Change this to true if you want to force copy

# Function to copy file to S3
copy_to_s3() {
    aws s3 cp "$LOCAL_FILE" "$S3_BUCKET/$S3_FILE_PATH"
    if [ $? -eq 0 ]; then
        echo "Copied $LOCAL_FILE to $S3_BUCKET/$S3_FILE_PATH"
    else
        echo "Failed to copy $LOCAL_FILE to $S3_BUCKET/$S3_FILE_PATH" >&2
    fi
}

# Check if the file does not exist in S3 or if override is true
if [ "$OVERRIDE" = true ] || ! aws s3 ls "$S3_BUCKET/$S3_FILE_PATH" > /dev/null 2>&1; then
    copy_to_s3
else
    echo "File $S3_BUCKET/$S3_FILE_PATH already exists, skipping copy."
fi



------------remove finalizer from Kafka topic---------
for cluster in $(kubectl get kafkas -n <namespace> -o jsonpath='{.items[*].metadata.name}'); do
  kubectl patch kafka $cluster -n <namespace> -p '{"metadata":{"finalizers":[]}}' --type=merge
done


------------init container sh----------
#!/bin/sh

process_files() {
  FILES=$1

  if [ -z "$FILES" ]; then
    echo "No files to process."
    return
  fi

  FILES=$(echo $FILES | jq -r '.[] | @base64')

  for file in $FILES; do
    _jq() {
      echo ${file} | base64 --decode | jq -r ${1}
    }

    SRC=$(_jq '.src')
    DEST=$(_jq '.dest')
    PERMISSIONS=$(_jq '.permissions')
    OVERRIDE=$(_jq '.override')

    if [ "$OVERRIDE" = "true" ]; then
      aws s3 cp "$SRC" "$DEST" --recursive
    else
      aws s3 sync "$SRC" "$DEST"
    fi

    chmod -R $PERMISSIONS $DEST
  done
}

# Process common files for all processes
process_files "$FILES_IN_ALL"

# Process common files for stateful or stateless processes
if [ "$PROCESS_TYPE" = "STATEFUL" ]; then
  process_files "$FILES_IN_STATEFUL"
elif [ "$PROCESS_TYPE" = "STATELESS" ]; then
  process_files "$FILES_IN_STATELESS"
fi

# Process specific files for the process
process_files "$FILES_IN_SPECIFIC"

-----------------------sidecar container sh-----------------
#!/bin/sh

process_files() {
  FILES=$1
  OVERRIDE=$2

  if [ -z "$FILES" ]; then
    echo "No files to process."
    return
  fi

  FILES=$(echo $FILES | jq -r '.[] | @base64')

  for file in $FILES; do
    _jq() {
      echo ${file} | base64 --decode | jq -r ${1}
    }

    SRC=$(_jq '.src')
    DEST=$(_jq '.dest')

    if [ "$OVERRIDE" = "true" ]; then
      aws s3 cp "$SRC" "$DEST" --recursive
    else
      aws s3 sync "$SRC" "$DEST"
    fi
  done
}

while true; do
  # Process common files for all processes
  process_files "$FILES_OUT_ALL" "$OVERRIDE_ALL"

  # Process common files for stateful or stateless processes
  if [ "$PROCESS_TYPE" = "STATEFUL" ]; then
    process_files "$FILES_OUT_STATEFUL" "$OVERRIDE_STATEFUL"
  elif [ "$PROCESS_TYPE" = "STATELESS" ]; then
    process_files "$FILES_OUT_STATELESS" "$OVERRIDE_STATELESS"
  fi

  # Process specific files for the process
  process_files "$FILES_OUT_SPECIFIC" "$OVERRIDE_SPECIFIC"

  sleep $INTERVAL
done


----------------values.yaml-------------
apiVersion: apps/v1
kind: {{ .Values.processes.type | title }}
metadata:
  name: {{ .Values.processes.name }}
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: {{ .Values.processes.name }}
    spec:
      volumes:
        - name: my-storage
          persistentVolumeClaim:
            claimName: my-pvc
      initContainers:
        - name: init-container
          image: amazon/aws-cli
          env:
            - name: FILES_IN_ALL
              value: '{{ toJson (index .Values.fileTransfers.transferIn.processes (index (pluck "processName" .Values.fileTransfers.transferIn.processes) "ALL") "files") | default "" }}'
            - name: FILES_IN_STATEFUL
              value: '{{ toJson (index .Values.fileTransfers.transferIn.processes (index (pluck "processName" .Values.fileTransfers.transferIn.processes) "STATEFUL") "files") | default "" }}'
            - name: FILES_IN_STATELESS
              value: '{{ toJson (index .Values.fileTransfers.transferIn.processes (index (pluck "processName" .Values.fileTransfers.transferIn.processes) "STATELESS") "files") | default "" }}'
            - name: FILES_IN_SPECIFIC
              value: '{{ toJson (index .Values.fileTransfers.transferIn.processes (index (pluck "processName" .Values.fileTransfers.transferIn.processes) .Values.processes.name) "files") | default "" }}'
            - name: PROCESS_TYPE
              value: '{{ .Values.processes.type | upper }}'
            - name: PROCESS_NAME
              value: '{{ .Values.processes.name }}'
          command: ["/bin/sh", "-c", "/init-container-script.sh"]
          volumeMounts:
            - name: my-storage
              mountPath: /mnt/data
      containers:
        - name: main-container
          image: nginx
          volumeMounts:
            - name: my-storage
              mountPath: /usr/share/nginx/html
        - name: sidecar-container
          image: amazon/aws-cli
          env:
            - name: FILES_OUT_ALL
              value: '{{ toJson (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) "ALL") "files") | default "" }}'
            - name: FILES_OUT_STATEFUL
              value: '{{ toJson (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) "STATEFUL") "files") | default "" }}'
            - name: FILES_OUT_STATELESS
              value: '{{ toJson (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) "STATELESS") "files") | default "" }}'
            - name: FILES_OUT_SPECIFIC
              value: '{{ toJson (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) .Values.processes.name) "files") | default "" }}'
            - name: OVERRIDE_ALL
              value: '{{ index (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) "ALL") "files") "override" | default "false" }}'
            - name: OVERRIDE_STATEFUL
              value: '{{ index (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) "STATEFUL") "files") "override" | default "false" }}'
            - name: OVERRIDE_STATELESS
              value: '{{ index (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) "STATELESS") "files") "override" | default "false" }}'
            - name: OVERRIDE_SPECIFIC
              value: '{{ index (index .Values.fileTransfers.transferOut.processes (index (pluck "processName" .Values.fileTransfers.transferOut.processes) .Values.processes.name) "files") "override" | default "false" }}'
            - name: INTERVAL
              value: '{{ index (pluck "interval" .Values.fileTransfers.intervals (index (pluck "processName" .Values.fileTransfers.intervals) .Values.processes.name)) 0 | default 60 }}'
            - name: PROCESS_TYPE
              value: '{{ .Values.processes.type | upper }}'
            - name: PROCESS_NAME
              value: '{{ .Values.processes.name }}'
          command: ["/bin/sh", "-c", "/sidecar-container-script.sh"]
          volumeMounts:
            - name: my-storage
              mountPath: /mnt/data
          env:
            - name: AWS_REGION
              value: us-east-1
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-secret
                  key: aws-access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-secret
                  key: aws-secret-access-key



----------------------------------------------------------------------------------------------------------------------------
#!/bin/bash

set -euo pipefail

if [ "$#" -lt 2 ]; then
  echo "Usage: $0 logicalName=<logical-group-name> namespace=<namespace>"
  exit 1
fi

# Parse arguments
for arg in "$@"; do
  case $arg in
    logicalName=*)
      LOGICAL_NAME="${arg#logicalName=}"
      ;;
    namespace=*)
      NAMESPACE="${arg#namespace=}"
      ;;
    *)
      echo "Invalid argument: $arg"
      exit 1
      ;;
  esac
done

if [ -z "$LOGICAL_NAME" ] || [ -z "$NAMESPACE" ]; then
  echo "Both logicalName and namespace are required."
  exit 1
fi

# Start timer
START_TIME=$(date +%s)

echo "Starting restore process for logical group: $LOGICAL_NAME in namespace: $NAMESPACE"

# Fetch VolumeSnapshots for the given logicalName
VOLUMESNAPSHOTS=($(kubectl get volumesnapshot -n "$NAMESPACE" -o json | jq -r --arg logicalName "$LOGICAL_NAME" '.items[] | select(.metadata.annotations.logicalGroupName == $logicalName and .metadata.annotations.backupStatus == "Success") | .metadata.name'))

if [ ${#VOLUMESNAPSHOTS[@]} -eq 0 ]; then
  echo "No successful VolumeSnapshots found for logical group: $LOGICAL_NAME"
  exit 1
fi

echo "Found ${#VOLUMESNAPSHOTS[@]} VolumeSnapshots to restore: ${VOLUMESNAPSHOTS[*]}"

# Scale down StatefulSets
STATEFULSETS=($(kubectl get statefulsets -n "$NAMESPACE" -o json | jq -r '.items[].metadata.name'))
for sts in "${STATEFULSETS[@]}"; do
  echo "Scaling down StatefulSet: $sts"
  kubectl scale statefulset "$sts" -n "$NAMESPACE" --replicas=0
done

# Wait for StatefulSets to scale down
echo "Waiting for StatefulSets to scale down..."
kubectl wait --for=delete pod -l app.kubernetes.io/instance="$LOGICAL_NAME" -n "$NAMESPACE" --timeout=300s

# Backup and Restore PVCs
declare -A ROLLBACK_SNAPSHOTS
for vs in "${VOLUMESNAPSHOTS[@]}"; do
  PVC_NAME=$(kubectl get volumesnapshot "$vs" -n "$NAMESPACE" -o jsonpath='{.spec.source.persistentVolumeClaimName}')
  
  echo "Creating backup snapshot for existing PVC: $PVC_NAME"
  BACKUP_SNAPSHOT_NAME="rollback-$PVC_NAME-$(date +%s)"
  cat <<EOF | kubectl apply -f -
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: $BACKUP_SNAPSHOT_NAME
  namespace: $NAMESPACE
spec:
  source:
    persistentVolumeClaimName: $PVC_NAME
EOF
  ROLLBACK_SNAPSHOTS["$PVC_NAME"]="$BACKUP_SNAPSHOT_NAME"

  # Wait for the backup snapshot to be ready
  kubectl wait --for=condition=ready volumesnapshot "$BACKUP_SNAPSHOT_NAME" -n "$NAMESPACE" --timeout=300s

  echo "Deleting existing PVC: $PVC_NAME"
  kubectl delete pvc "$PVC_NAME" -n "$NAMESPACE"

  echo "Restoring PVC: $PVC_NAME from VolumeSnapshot: $vs"
  cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: $PVC_NAME
  namespace: $NAMESPACE
  annotations:
    restoreStatus: "InProgress"
spec:
  dataSource:
    name: $vs
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  storageClassName: <your-storage-class>
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: <desired-storage-size>
EOF
done

# Wait for all PVCs to bind
echo "Waiting for PVCs to bind..."
for vs in "${VOLUMESNAPSHOTS[@]}"; do
  PVC_NAME=$(kubectl get volumesnapshot "$vs" -n "$NAMESPACE" -o jsonpath='{.spec.source.persistentVolumeClaimName}')
  kubectl wait --for=condition=Bound pvc "$PVC_NAME" -n "$NAMESPACE" --timeout=300s
done

# Update restore status annotations
for vs in "${VOLUMESNAPSHOTS[@]}"; do
  kubectl annotate volumesnapshot "$vs" -n "$NAMESPACE" restoreStatus="Success" --overwrite
done

# Scale up StatefulSets
for sts in "${STATEFULSETS[@]}"; do
  echo "Scaling up StatefulSet: $sts"
  kubectl scale statefulset "$sts" -n "$NAMESPACE" --replicas=1
done

# Wait for StatefulSets to scale up
echo "Waiting for StatefulSets to scale up..."
for sts in "${STATEFULSETS[@]}"; do
  kubectl rollout status statefulset "$sts" -n "$NAMESPACE" --timeout=300s
done

# End timer
END_TIME=$(date +%s)
TOTAL_TIME=$((END_TIME - START_TIME))

echo "Restore process completed successfully in $TOTAL_TIME seconds."

# Cleanup rollback snapshots if everything is successful
echo "Cleaning up rollback snapshots..."
for snapshot in "${ROLLBACK_SNAPSHOTS[@]}"; do
  kubectl delete volumesnapshot "$snapshot" -n "$NAMESPACE"
done

